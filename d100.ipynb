{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "class FNN(nn.Module):\n",
    "    '''Full-Connected Neural Network with Batch Normalization'''\n",
    "    def __init__(self, input_dim: int, num_hiddens, output_dim: int, activate_fun, device=torch.device(\"cpu\")):\n",
    "        super(FNN, self).__init__()\n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.activate_fun = activate_fun\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        self.dense_layers = nn.ModuleList()\n",
    "        self.batch_norms = nn.ModuleList() \n",
    "        \n",
    "        self.dense_layers.append(nn.Linear(input_dim, num_hiddens[0]))\n",
    "        self.batch_norms.append(nn.BatchNorm1d(num_hiddens[0]))\n",
    "\n",
    "        for i in range(len(num_hiddens) - 1):\n",
    "            self.dense_layers.append(nn.Linear(num_hiddens[i], num_hiddens[i+1]))\n",
    "            self.batch_norms.append(nn.BatchNorm1d(num_hiddens[i+1]))\n",
    "\n",
    "        self.dense_layers.append(nn.Linear(num_hiddens[-1], output_dim))\n",
    "\n",
    "        self.to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i in range(len(self.dense_layers) - 1): \n",
    "            x = self.dense_layers[i](x)\n",
    "            x = self.batch_norms[i](x)\n",
    "            x = self.activate_fun(x)\n",
    "        \n",
    "        x = self.dense_layers[-1](x)\n",
    "        return x\n",
    "    \n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sample_path(n_sample, d, n_time, h, lam, delta, device='cpu'):\n",
    "    sqrth = torch.sqrt(torch.tensor(h))\n",
    "    \n",
    "    dW_sample = torch.zeros(n_sample, d, n_time)\n",
    "    Jumps_sample = torch.zeros(n_sample, d, n_time)\n",
    "    X_sample = torch.ones(n_sample, d, n_time + 1)\n",
    "    \n",
    "    for i in range(n_time):\n",
    "        dW_sample[:, :, i] = torch.normal(mean=0.0, std=1.0, size=(n_sample, d)) * sqrth\n",
    "        P_sample = torch.poisson(torch.full((n_sample * d,), lam * h))\n",
    "        Jumps_sample[:, :, i] = torch.tensor(\n",
    "            [torch.sum(torch.empty(int(k)).uniform_(-delta, delta)) for k in P_sample]\n",
    "        ).reshape(n_sample, d)\n",
    "        \n",
    "        X_sample[:, :, i+1] = X_sample[:, :, i] \\\n",
    "            + torch.cos(X_sample[:, :, i]) * h \\\n",
    "            + dW_sample[:, :, i] \\\n",
    "            + Jumps_sample[:, :, i]\n",
    "    \n",
    "    dW_sample = dW_sample.to(device)\n",
    "    Jumps_sample = Jumps_sample.to(device)\n",
    "    X_sample = X_sample.to(device)\n",
    "    \n",
    "    return dW_sample, X_sample, Jumps_sample\n",
    "\n",
    "\n",
    "def f(t, X, Y, Z,U, d, delta):   \n",
    "    term0 = torch.exp(t) * torch.mean(torch.sin(X), dim=1, keepdim=True)\n",
    "    term1 = 0.5 * term0\n",
    "    term2 = torch.sum(Z*torch.cos(X), dim=1, keepdim=True)\n",
    "\n",
    "    u1 = torch.mean(torch.cos(X-delta)-torch.cos(X+delta),dim=1,keepdim=True)\n",
    "    U_term = (2*delta)**2 * torch.exp(t) *  u1  - (2*delta)**2 * term0 * (2*delta)**d\n",
    "    result = -(Y - term1 + term2 + U_term)\n",
    "    return result\n",
    "\n",
    "def g(t, X):\n",
    "    output = torch.exp(t) * torch.mean(torch.sin(X),dim=1,keepdim=True)\n",
    "    return output\n",
    "\n",
    "def test_loss(dW_sample, X_sample, time_grid, delta, h, device='cpu'):\n",
    "    _, d, n_time = dW_sample.shape\n",
    "    Y = g(time_grid[0], X_sample[:, :, 0])\n",
    "    loss_his = []\n",
    "    for i in range(n_time):\n",
    "        Z = torch.exp(time_grid[i]) * torch.cos(X_sample[:, :, i])/d\n",
    "        Y = Y - f(time_grid[i], X_sample[:, :, i], Y, Z, torch.zeros_like(Y), d, delta) * h\n",
    "        Y = Y + torch.sum(Z * dW_sample[:, :, i], dim=1, keepdim=True)\n",
    "        loss_his.append(torch.mean((Y - g(time_grid[i+1], X_sample[:, :, i+1]))**2).item())\n",
    "    plt.plot(loss_his)\n",
    "    plt.yscale('log')\n",
    "    plt.show()\n",
    "\n",
    "    return loss_his[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 2024\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "T = 1\n",
    "d = 100 \n",
    "n_time = 10\n",
    "\n",
    "delta = 0.1    # jump size\n",
    "lam = (2*delta)**2    # jump activity\n",
    "\n",
    "h = T/n_time\n",
    "n_sample = 64\n",
    "time_grid = torch.linspace(0, T, n_time + 1,device=device)\n",
    "\n",
    "# Generate the sample paths\n",
    "dW_sample, X_sample, Jumps_sample = sample_path(n_sample, d, n_time, h, lam, delta, \n",
    "                                                device=device)\n",
    "Y_sample = torch.zeros(n_sample, 1, n_time+1)\n",
    "for i in range(n_time+1):\n",
    "    Y_sample[:, :, i] = g(time_grid[i], X_sample[:, :, i])\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(n_sample):\n",
    "    plt.plot(time_grid.cpu(), Y_sample[i, 0, :])\n",
    "\n",
    "plt.xlabel('t')\n",
    "plt.ylabel('u')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "print('y0',Y_sample[:,:,0].mean().item())\n",
    "print('test_loss',test_loss(dW_sample, X_sample,time_grid, delta, h, device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelList_Z = [FNN(input_dim=d, \n",
    "                   num_hiddens=[d+10,d+10,d+10], \n",
    "                   output_dim = 1, \n",
    "                   activate_fun=nn.ReLU(),\n",
    "                   device=device) \n",
    "               for i in range(n_time-1)]\n",
    "modelList_U = [FNN(input_dim=d, \n",
    "                   num_hiddens=[d+10,d+10], \n",
    "                   output_dim = 1, \n",
    "                   activate_fun=nn.ReLU(),\n",
    "                   device=device) \n",
    "               for i in range(n_time-1)]\n",
    "\n",
    "y_init = torch.nn.Parameter(torch.empty(1, 1, device=device).uniform_(0.82,0.83))\n",
    "z_init = torch.nn.Parameter(torch.empty(1, d, device=device).uniform_(-0.1, 0.1))\n",
    "u_init = torch.nn.Parameter(torch.empty(1, 1, device=device).uniform_(-0.2, 0.2))\n",
    "\n",
    "\n",
    "def loss_fun(dW_sample, X_sample, Jumps_sample):\n",
    "    Y = torch.ones((n_sample,1), device=device) @ y_init\n",
    "    Z = torch.ones((n_sample,1), device=device) @ z_init\n",
    "    U = torch.ones((n_sample,1), device=device) @ u_init\n",
    "\n",
    "    for i in range(n_time):\n",
    "        Y = Y - f(time_grid[i], X_sample[:, :, i], Y, Z,U, d, delta) * h\n",
    "        Y = Y + torch.sum(Z * dW_sample[:, :, i], dim=1, keepdim=True) + U\n",
    "\n",
    "        if i < n_time - 1:\n",
    "            Z = modelList_Z[i](X_sample[:, :, i + 1])\n",
    "            U = modelList_U[i](Z * Jumps_sample[:, :, i])\n",
    "    \n",
    "    term_delta = Y - g(time_grid[i+1], X_sample[:,:,i+1])\n",
    "    clamp_term_delta = torch.clamp(term_delta, -50, 50) \n",
    "    loss = torch.mean(clamp_term_delta**2)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "params = [y_init, z_init, u_init]\n",
    "\n",
    "for model in modelList_Z:\n",
    "    params += list(model.parameters())\n",
    "\n",
    "for model in modelList_U:\n",
    "    params += list(model.parameters())\n",
    "\n",
    "optimizer = torch.optim.Adam(params, lr=0.0005)\n",
    "\n",
    "\n",
    "# Define the learning rate schedule function\n",
    "def lr_lambda(step):\n",
    "    if step < 4000:\n",
    "        return 0.0005 / 0.0005  # Keeps the learning rate at 0.0005\n",
    "    elif 4000 <= step < 5000:\n",
    "        return 0.0001 / 0.0005  # Adjust to 0.0001\n",
    "    elif 5000 <= step < 6500:\n",
    "        return 0.00005 / 0.0005  # Adjust to 0.00005\n",
    "    else:\n",
    "        return 0.00001 / 0.0005  # Adjust to 0.00005\n",
    "\n",
    "# Create the LambdaLR scheduler\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "train_his = []\n",
    "\n",
    "for i in range(7000):\n",
    "    dW_sample, X_sample, Jumps_sample = sample_path(n_sample, d, n_time, h, lam, delta,\n",
    "                                                    device=device)\n",
    "    loss = loss_fun(dW_sample, X_sample, Jumps_sample)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "\n",
    "    if (i+1) % 100 == 0 or i == 0:\n",
    "        print(f'iter:{i+1}, loss:{loss.item():.4e}, time:{time.time()-start_time:.2f}, y0:{torch.mean(y_init).item():.4f},lr:{optimizer.param_groups[0][\"lr\"]:.4f}')\n",
    "        train_his.append({'iter':i+1, 'loss': loss.item(), 'y0': torch.mean(y_init).item(), 'time': time.time()-start_time, 'lr': optimizer.param_groups[0]['lr']})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([i['iter'] for i in train_his], [i['loss'] for i in train_his])\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([i['iter'] for i in train_his], [i['y0'] for i in train_his])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(train_his)\n",
    "df.to_csv('d100-sum_train_his.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PINN-torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
