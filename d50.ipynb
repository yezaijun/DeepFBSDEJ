{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "class FNN(nn.Module):\n",
    "    '''Full-Connected Neural Network with Batch Normalization'''\n",
    "    def __init__(self, input_dim: int, num_hiddens, output_dim: int, activate_fun, device=torch.device(\"cpu\")):\n",
    "        super(FNN, self).__init__()\n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.activate_fun = activate_fun\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        self.dense_layers = nn.ModuleList()\n",
    "        self.dense_layers.append(nn.Linear(input_dim, num_hiddens[0]))\n",
    "\n",
    "        # 添加隐藏层\n",
    "        for i in range(len(num_hiddens) - 1):\n",
    "            self.dense_layers.append(nn.Linear(num_hiddens[i], num_hiddens[i+1]))\n",
    "        \n",
    "        self.dense_layers.append(nn.Linear(num_hiddens[-1], output_dim))\n",
    "\n",
    "        self.to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i in range(len(self.dense_layers) - 1):\n",
    "            x = self.dense_layers[i](x)\n",
    "            x = self.activate_fun(x)\n",
    "        x = self.dense_layers[-1](x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def set_seed(seed):\n",
    "    # set random seed\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(2024)\n",
    "\n",
    "# default start time is 0\n",
    "T = 1 # total time\n",
    "d = 50 # dimension\n",
    "n_time = 100 # time interval number\n",
    "\n",
    "r_eq = 0.1\n",
    "sigma_eq = 0.3\n",
    "d_eq = 0.1\n",
    "\n",
    "lam = 0.1    # jump activity\n",
    "delta = 0.5   # jump size\n",
    "\n",
    "h = T/n_time # time interval step\n",
    "n_sample = 128\n",
    "time_grid = torch.linspace(0, T, n_time + 1)\n",
    "\n",
    "x0 = torch.pi/2\n",
    "\n",
    "device = 'cuda'\n",
    "\n",
    "def sample_path(n_sample, d, n_time, h, lam, delta, device = 'cpu'):\n",
    "    sqrth = torch.sqrt(torch.tensor(h))\n",
    "    \n",
    "    dW_sample = torch.zeros(n_sample, d, n_time)\n",
    "    Jumps_sample = torch.zeros(n_sample, d, n_time)\n",
    "    \n",
    "    for i in range(n_time):\n",
    "        dW_sample[:, :, i] = torch.normal(mean=0.0, std=1.0, size=(n_sample, d)) * sqrth\n",
    "        P_sample = torch.poisson(torch.full((n_sample * d,), lam * h))\n",
    "        Jumps_sample[:, :, i] = torch.tensor(\n",
    "            [torch.sum(torch.empty(int(k)).uniform_(-delta, delta)) for k in P_sample]\n",
    "        ).reshape(n_sample, d)\n",
    "    \n",
    "    dW_sample = dW_sample.to(device)\n",
    "    Jumps_sample = Jumps_sample.to(device)\n",
    "    return dW_sample, Jumps_sample\n",
    "\n",
    "def f(t, X, Y, Z, U):\n",
    "    # nonlinear term\n",
    "    term1 = - r_eq * Y \n",
    "    term2 = 0.5 * torch.exp(-3 * r_eq * (T - t) )* sigma_eq**2 * (d_eq * torch.sum(torch.sin(X), dim=1, keepdim=True))**3\n",
    "    result = term1 + term2 + U\n",
    "    return result\n",
    "\n",
    "def g(t, X):\n",
    "    # terminal conditions\n",
    "    output = torch.exp(- r_eq * (T - t)) * d_eq * torch.sum(torch.sin(X), dim=1, keepdim=True)\n",
    "    return output\n",
    "\n",
    "modelList_Z = [FNN(input_dim=d, \n",
    "                   num_hiddens=[128, 128], \n",
    "                   output_dim = d, \n",
    "                   activate_fun=nn.ReLU(),\n",
    "                   device=device) \n",
    "               for i in range(n_time-1)]\n",
    "modelList_U = [FNN(input_dim=d, \n",
    "                   num_hiddens=[128, 128], \n",
    "                   output_dim = 1, \n",
    "                   activate_fun=nn.ReLU(),\n",
    "                   device=device) \n",
    "               for i in range(n_time-1)]\n",
    "\n",
    "y_init = torch.nn.Parameter(torch.empty(1, 1,device=device).uniform_(3, 4))\n",
    "z_init = torch.nn.Parameter(torch.empty(1, d,device=device).uniform_(-0.1, 0.1))\n",
    "u_init = torch.nn.Parameter(torch.empty(1, 1,device=device).uniform_(-0.1, 0.1))\n",
    "\n",
    "def loss_fun(dW_sample, Jumps_sample):\n",
    "    X = torch.ones((n_sample,d),device=device) * x0\n",
    "    Y = torch.ones((n_sample,1),device=device) * y_init\n",
    "    Z = torch.ones((n_sample,1),device=device) * z_init\n",
    "    U = torch.ones((n_sample,1),device=device) * u_init\n",
    "\n",
    "    for i in range(n_time):\n",
    "        Y = Y - f(time_grid[i], X, Y, Z, U) * h\n",
    "        Y = Y + sigma_eq * Y * torch.sum(Z * dW_sample[:, :, i],dim=1,keepdim=True) + U * h\n",
    "        X = X + sigma_eq * Y * dW_sample[:, :, i] + Jumps_sample[:, :, i]\n",
    "\n",
    "        if i < n_time - 1:\n",
    "            Z = modelList_Z[i](X)\n",
    "            U = modelList_U[i](Z * Jumps_sample[:, :, i])\n",
    "\n",
    "    term_delta = Y - g(time_grid[i+1], X) \n",
    "    clamp_term_delta = torch.clamp(term_delta, -50, 50)\n",
    "    loss = torch.mean(clamp_term_delta**2)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "params = [y_init, z_init, u_init] \n",
    "for model in modelList_Z:\n",
    "    params += list(model.parameters())\n",
    "for model in modelList_U:\n",
    "    params += list(model.parameters())\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(params, lr=0.002)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=200, gamma=0.8)\n",
    "\n",
    "\n",
    "truth_value = g(torch.zeros((1,1)), torch.ones((1,d))*torch.pi/2)\n",
    "print(truth_value)\n",
    "\n",
    "start_time = time.time()\n",
    "train_his = []\n",
    "\n",
    "for iter in range(1500):\n",
    "    dW_sample, Jumps_sample = sample_path(n_sample, d, n_time, h, lam, delta,device=device)  \n",
    "    optimizer.zero_grad()\n",
    "    loss = loss_fun(dW_sample, Jumps_sample)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    if (iter+1) % 10 == 0 or iter == 0:\n",
    "        g_error = torch.mean((torch.abs((truth_value-y_init.detach().cpu())/truth_value)))\n",
    "\n",
    "        print(f'iter:{iter+1}, loss:{loss.item():.4e}, time:{time.time()-start_time:.2f}, y0:{torch.mean(y_init).item():.4f}, error:{g_error:.4f},lr:{optimizer.param_groups[0][\"lr\"]:.4f}')\n",
    "        train_his.append({'iter':iter+1,'loss': loss.item(), 'y0': torch.mean(y_init).item(), 'time': time.time()-start_time, 'error':g_error,'lr':optimizer.param_groups[0][\"lr\"]})\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.DataFrame(train_his)\n",
    "df['iter'] = df.index*10\n",
    "# 输出DataFrame\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df['iter'],df['loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制损失、y0\n",
    "plt.plot(df['iter'],df['error'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_size = 300\n",
    "df_sampled = df[df['iter'] % step_size == 0]\n",
    "\n",
    "summary_df = pd.DataFrame({\n",
    "    'Iteration': df_sampled['iter'],\n",
    "    'Loss': df_sampled['loss'],\n",
    "    'y0': df_sampled['y0'],\n",
    "    'error': df_sampled['error'],\n",
    "})\n",
    "latex_table = summary_df.to_latex(index=False, float_format=\"%.4f\", column_format='cccc', header=True)\n",
    "\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PINN-torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
