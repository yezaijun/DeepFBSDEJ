{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FNN(nn.Module):\n",
    "    '''Full-Connected Neural Network with Batch Normalization'''\n",
    "    def __init__(self, input_dim: int, num_hiddens, output_dim: int, activate_fun, device=torch.device(\"cpu\")):\n",
    "        super(FNN, self).__init__()\n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.activate_fun = activate_fun\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        self.dense_layers = nn.ModuleList()\n",
    "        self.dense_layers.append(nn.Linear(input_dim, num_hiddens[0]))\n",
    "\n",
    "        # 添加隐藏层\n",
    "        for i in range(len(num_hiddens) - 1):\n",
    "            self.dense_layers.append(nn.Linear(num_hiddens[i], num_hiddens[i+1]))\n",
    "        \n",
    "        self.dense_layers.append(nn.Linear(num_hiddens[-1], output_dim))\n",
    "\n",
    "        self.to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i in range(len(self.dense_layers) - 1):\n",
    "            x = self.dense_layers[i](x)\n",
    "            x = self.activate_fun(x)\n",
    "        x = self.dense_layers[-1](x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_path(n_sample, d, n_time, h, lam, delta, mu, sig):\n",
    "    sqrth = torch.sqrt(torch.tensor(h))\n",
    "    \n",
    "    dW_sample = torch.zeros(n_sample, d, n_time)\n",
    "    Jumps_sample = torch.zeros(n_sample, d, n_time)\n",
    "    X_sample = torch.zeros(n_sample, d, n_time + 1)\n",
    "    \n",
    "    for i in range(n_time):\n",
    "        dW_sample[:, :, i] = torch.normal(mean=0.0, std=1.0, size=(n_sample, d)) * sqrth\n",
    "        P_sample = torch.poisson(torch.full((n_sample * d,), lam * h))\n",
    "        Jumps_sample[:, :, i] = torch.tensor(\n",
    "            [torch.sum(torch.empty(int(k)).uniform_(-delta, delta)) for k in P_sample]\n",
    "        ).reshape(n_sample, d)\n",
    "        \n",
    "        X_sample[:, :, i+1] = X_sample[:, :, i] + mu * h + \\\n",
    "            sig * dW_sample[:, :, i] + Jumps_sample[:, :, i]\n",
    "    \n",
    "    return dW_sample, X_sample, Jumps_sample\n",
    "\n",
    "def f(t, X, Y, Z, U, delta = 1):\n",
    "    # nonlinear term\n",
    "    exp_term = torch.exp(torch.sin(X + t) + 2.0)\n",
    "    term1 = (Y - 2.0) * torch.exp(Y) / (2.0 * exp_term)\n",
    "    term2 = torch.sum(Z, dim=1, keepdim=True) * Y / exp_term\n",
    "    result = term1 - term2 - U\n",
    "    return result\n",
    "\n",
    "def g(t, X):\n",
    "    # terminal conditions\n",
    "    output = torch.sin(X + t) + 2.0\n",
    "    return output\n",
    "\n",
    "def dg_dx(t,x):\n",
    "    return torch.cos(x+t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed\n",
    "seed = 2024\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "# default start time is 0\n",
    "T = 1 # total time\n",
    "d = 1 # dimension\n",
    "n_time = 20 # time interval number\n",
    "mu = 0   # drift \n",
    "sig = 1.0 # diffusion coefficient\n",
    "lam = 2    # jump activity\n",
    "delta = 1    # jump size\n",
    "\n",
    "\n",
    "h = T/n_time # time interval step\n",
    "n_sample = 64\n",
    "time_grid = np.linspace(0, T, n_time + 1)\n",
    "\n",
    "# Generate the sample paths\n",
    "dW_sample, X_sample, Jumps_sample = sample_path(n_sample, d, n_time, h, lam, delta, mu, sig)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(n_sample):\n",
    "    plt.plot(time_grid, X_sample[i, 0, :])\n",
    "\n",
    "plt.title('Sample Paths of X(t)')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('X(t)')\n",
    "# plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelList_Z = [FNN(input_dim=d, \n",
    "                   num_hiddens=[11,11], \n",
    "                   output_dim = 1, \n",
    "                   activate_fun=nn.ReLU()) \n",
    "               for i in range(n_time-1)]\n",
    "modelList_U = [FNN(input_dim=d, \n",
    "                   num_hiddens=[11,11], \n",
    "                   output_dim = 1, \n",
    "                   activate_fun=nn.ReLU()) \n",
    "               for i in range(n_time-1)]\n",
    "\n",
    "y_init = torch.nn.Parameter(torch.empty(1, 1).uniform_(1.75, 1.85))\n",
    "z_init = torch.nn.Parameter(torch.empty(1, 1).uniform_(0.7, 0.8))\n",
    "u_init = torch.nn.Parameter(torch.empty(1, 1).uniform_(-0.2, 0.2))\n",
    "\n",
    "\n",
    "def loss_fun(dW_sample, X_sample, Jumps_sample):\n",
    "    Y = torch.ones((n_sample,1)) *y_init\n",
    "    Z = torch.ones((n_sample,1)) *z_init\n",
    "    U = torch.ones((n_sample,1)) *u_init\n",
    "\n",
    "\n",
    "    for i in range(n_time):\n",
    "        Y = Y - f(time_grid[i], X_sample[:, :, i], Y, Z, U, delta) * h\n",
    "        Y = Y + Z * dW_sample[:, :, i] + U*h\n",
    "\n",
    "        if i < n_time - 1:\n",
    "            Z = modelList_Z[i](X_sample[:, :, i + 1])\n",
    "            U = modelList_U[i](Z * Jumps_sample[:, :, i])\n",
    "\n",
    "    term_delta = Y - g(time_grid[i+1], X_sample[:,:,i+1]) \n",
    "    clamp_term_delta = torch.clamp(term_delta, -50, 50)\n",
    "    loss = torch.mean(clamp_term_delta**2)\n",
    "    \n",
    "    return loss\n",
    "   \n",
    "def error_dgdx(X_sample):\n",
    "    with torch.no_grad():\n",
    "        dgdx_error = []\n",
    "        for i in range(n_time-1):\n",
    "            nn_result = modelList_Z[i](X_sample[:, :, i + 1])\n",
    "            fun_result = dg_dx(time_grid[i+1],X_sample[:, :, i + 1])\n",
    "            error = torch.mean(torch.abs(nn_result - fun_result))\n",
    "            dgdx_error.append(error.item())\n",
    "    return np.mean(dgdx_error)\n",
    "\n",
    "\n",
    "params = [y_init, z_init, u_init] \n",
    "\n",
    "for model in modelList_Z:\n",
    "    params += list(model.parameters())\n",
    "\n",
    "for model in modelList_U:\n",
    "    params += list(model.parameters())\n",
    "\n",
    "optimizer = torch.optim.Adam(params, lr=0.0005)\n",
    "\n",
    "start_time = time.time()\n",
    "train_his = []\n",
    "\n",
    "for i in range(4000):\n",
    "    dW_sample, X_sample, Jumps_sample = sample_path(n_sample, d, n_time, h, lam, delta, mu, sig)  \n",
    "\n",
    "    loss = loss_fun(dW_sample, X_sample, Jumps_sample)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (i+1) % 100 == 0 or i == 0:\n",
    "        dgdx_error = error_dgdx(X_sample)\n",
    "\n",
    "        print(f'iter:{i+1}, loss:{loss.item():.4e}, time:{time.time()-start_time:.2f}, y0:{torch.mean(y_init).item():.4f}, z_error:{dgdx_error:.4f}')\n",
    "        train_his.append({'iter':i+1,'loss': loss.item(), 'y0': torch.mean(y_init).item(), 'time': time.time()-start_time, 'z_error':dgdx_error})\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([i['iter'] for i in train_his], [i['loss'] for i in train_his])\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制损失、y0\n",
    "plt.plot([i['iter'] for i in train_his], [i['z_error'] for i in train_his])\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(train_his)\n",
    "df.to_csv(f'd1_train_his_{seed}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([i['iter'] for i in train_his], [i['z_error'] for i in train_his])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Mean Absolute Error of $\\\\nabla u$')\n",
    "plt.savefig('d1-z_error.pdf',dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 2\n",
    "df['loss_smooth'] = df['loss'].rolling(window=window_size).mean()\n",
    "df.loc[df['loss_smooth'].isna(), 'loss_smooth'] = df['loss'].iloc[0]\n",
    "df.loc[0, 'iter'] = 0\n",
    "\n",
    "plt.plot(df['iter'],df['loss_smooth'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.savefig('d1-loss.pdf',dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['relativeL1error'] = abs(df['y0']-2)/df['y0']\n",
    "window_size = 2\n",
    "df['relativeL1error_smooth'] = df['relativeL1error'].rolling(window=window_size).mean()\n",
    "df.loc[df['relativeL1error_smooth'].isna(), 'relativeL1error_smooth'] = df['relativeL1error'].iloc[0]\n",
    "\n",
    "plt.plot(df['iter'],df['relativeL1error_smooth'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Error')\n",
    "plt.savefig('d1-error.pdf',dpi=300)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DBDP-torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
